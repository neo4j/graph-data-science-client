{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d08c597a9fdbf3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Knowledge Graph Embedding: DistMult embedding for Nation dataset\n",
    "\n",
    "In this notebook, we will use the DistMult embedding model to make predictions on the Nations dataset.\n",
    "The Nations dataset is a simple dataset that contains relationships between countries.\n",
    "\n",
    "The dataset contains three files: `train.txt`, `valid.txt`, and `test.txt`.\n",
    "Each file contains triplets of the form `source_country relation target_country`.\n",
    "The `entity2id.txt` file contains the mapping of country names to ids, and the `relation2id.txt` file contains the mapping of relation names to ids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9529174",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We start by installing and importing our dependencies, and setting up our GDS client connection to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135277efcde2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from neo4j.exceptions import ClientError\n",
    "from tqdm import tqdm\n",
    "from graphdatascience import GraphDataScience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551fddc3a67fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f05ee7fdb496f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = os.environ.get(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_AUTH = None\n",
    "NEO4J_DB = os.environ.get(\"NEO4J_DB\", \"neo4j\")\n",
    "if os.environ.get(\"NEO4J_USER\") and os.environ.get(\"NEO4J_PASSWORD\"):\n",
    "    NEO4J_AUTH = (\n",
    "        os.environ.get(\"NEO4J_USER\"),\n",
    "        os.environ.get(\"NEO4J_PASSWORD\"),\n",
    "    )\n",
    "gds = GraphDataScience(NEO4J_URI, auth=NEO4J_AUTH, database=NEO4J_DB, arrow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a7f9b7",
   "metadata": {},
   "source": [
    "Create constraints to ensure that the `Entity` nodes have unique `text` properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658c9f8369fff77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _ = gds.run_cypher(\"CREATE CONSTRAINT entity_id FOR (e:Entity) REQUIRE e.text IS UNIQUE\")\n",
    "except ClientError:\n",
    "    print(\"CONSTRAINT entity_id already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f3ded",
   "metadata": {},
   "source": [
    "## Download and read the data\n",
    "\n",
    "Let's download the Nations dataset and read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485869468ad5ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_to_id_map(data_dir, text_to_id_filename):\n",
    "    with open(data_dir + \"/\" + text_to_id_filename, \"r\") as f:\n",
    "        data = [x.split(\"\\t\") for x in f.read().split(\"\\n\")[:-1]]\n",
    "    text_to_id_map = {text: int(id) for text, id in data}\n",
    "    return text_to_id_map\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    rel_types = {\n",
    "        \"train.txt\": \"TRAIN\",\n",
    "        \"valid.txt\": \"VALID\",\n",
    "        \"test.txt\": \"TEST\",\n",
    "    }\n",
    "    url = \"https://raw.githubusercontent.com/ZhenfengLei/KGDatasets/master/Nations\"\n",
    "    data_dir = \"./Nations\"\n",
    "\n",
    "    raw_file_names = [\"train.txt\", \"valid.txt\", \"test.txt\"]\n",
    "    node_id_filename = \"entity2id.txt\"\n",
    "    rel_id_filename = \"relation2id.txt\"\n",
    "\n",
    "    for file in raw_file_names + [node_id_filename, rel_id_filename]:\n",
    "        if not os.path.exists(f\"{data_dir}/{file}\"):\n",
    "            os.system(f\"wget {url}/{file} -P {data_dir}\")\n",
    "\n",
    "    node_map = get_text_to_id_map(data_dir, node_id_filename)\n",
    "    rel_map = get_text_to_id_map(data_dir, rel_id_filename)\n",
    "    dataset = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    rel_split_id = {\"TRAIN\": 0, \"VALID\": 1, \"TEST\": 2}\n",
    "\n",
    "    for file_name in raw_file_names:\n",
    "        file_name_path = data_dir + \"/\" + file_name\n",
    "\n",
    "        with open(file_name_path, \"r\") as f:\n",
    "            data = [x.split(\"\\t\") for x in f.read().split(\"\\n\")[:-1]]\n",
    "\n",
    "        for i, (src_text, rel_text, dst_text) in enumerate(data):\n",
    "            source = node_map[src_text]\n",
    "            target = node_map[dst_text]\n",
    "            rel_type = \"REL_\" + rel_text.upper()\n",
    "            rel_split = rel_types[file_name]\n",
    "\n",
    "            dataset[rel_split][rel_type].append(\n",
    "                {\n",
    "                    \"source\": source,\n",
    "                    \"source_text\": src_text,\n",
    "                    \"target\": target,\n",
    "                    \"target_text\": dst_text,\n",
    "                    \"rel_type\": rel_type,\n",
    "                    \"rel_id\": rel_map[rel_text],\n",
    "                    \"rel_split\": rel_split,\n",
    "                    \"rel_split_id\": rel_split_id[rel_split],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    print(\"Number of nodes: \", len(node_map))\n",
    "    for rel_split in dataset:\n",
    "        print(\n",
    "            f\"Number of relationships of type {rel_split}: \",\n",
    "            sum([len(dataset[rel_split][rel_type]) for rel_type in dataset[rel_split]]),\n",
    "        )\n",
    "    return dataset, node_map\n",
    "\n",
    "\n",
    "dataset, node_map = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97b4df",
   "metadata": {},
   "source": [
    "## Put data in the database\n",
    "\n",
    "We will put the data in the database, creating `Entity` nodes and relationships between them.\n",
    "\n",
    "Each node will have a `text` property. We will use `text` to identify the node later.\n",
    "\n",
    "Each relationship will have a `split` property to indicate whether it is part of the training, validation, or test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032a4e1aed1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_data_in_db():\n",
    "    res = gds.run_cypher(\"MATCH (m) RETURN count(m) as num_nodes\")\n",
    "    if res[\"num_nodes\"].values[0] > 0:\n",
    "        print(\"Data already in db, number of nodes: \", res[\"num_nodes\"].values[0])\n",
    "        return\n",
    "    pbar = tqdm(\n",
    "        desc=\"Putting data in db\",\n",
    "        total=sum([len(dataset[rel_split][rel_type]) for rel_split in dataset for rel_type in dataset[rel_split]]),\n",
    "    )\n",
    "\n",
    "    for rel_split in dataset:\n",
    "        for rel_type in dataset[rel_split]:\n",
    "            edges = dataset[rel_split][rel_type]\n",
    "\n",
    "            gds.run_cypher(\n",
    "                f\"\"\"\n",
    "                UNWIND $ll as l\n",
    "                MERGE (n:Entity {{id:l.source, text:l.source_text}})\n",
    "                MERGE (m:Entity {{id:l.target, text:l.target_text}})\n",
    "                MERGE (n)-[:{rel_type} {{split: l.rel_split_id, rel_id: l.rel_id}}]->(m)\n",
    "                \"\"\",\n",
    "                params={\"ll\": edges},\n",
    "            )\n",
    "            pbar.update(len(edges))\n",
    "    pbar.close()\n",
    "\n",
    "    for rel_split in dataset:\n",
    "        res = gds.run_cypher(\n",
    "            f\"\"\"\n",
    "            MATCH ()-[r:{rel_split}]->()\n",
    "            RETURN COUNT(r) AS numberOfRelationships\n",
    "            \"\"\"\n",
    "        )\n",
    "        print(f\"Number of relationships of type {rel_split} in db: \", res.numberOfRelationships)\n",
    "\n",
    "\n",
    "put_data_in_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f270636",
   "metadata": {},
   "source": [
    "## Project graphs\n",
    "\n",
    "First, we will project the full graph, then we will filter the graph to create the training graph based on the `split` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f1523a225fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_graphs():\n",
    "    all_rels = gds.run_cypher(\n",
    "        \"\"\"\n",
    "            CALL db.relationshipTypes() YIELD relationshipType\n",
    "        \"\"\"\n",
    "    )\n",
    "    all_rels = all_rels[\"relationshipType\"].to_list()\n",
    "    all_rels = {rel: {\"properties\": \"split\"} for rel in all_rels if rel.startswith(\"REL_\")}\n",
    "    gds.graph.drop(\"fullGraph\", failIfMissing=False)\n",
    "\n",
    "    G_full, _ = gds.graph.project(\"fullGraph\", [\"Entity\"], all_rels)\n",
    "\n",
    "    return G_full\n",
    "\n",
    "\n",
    "G = project_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da1ea76d247803",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.relationship_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b243ea",
   "metadata": {},
   "source": [
    "We will train a knowledge graph embedding model using the Graph Data Science library. The model will be trained on the `G` graph.\n",
    "\n",
    "We will use the DistMult scoring function and set the embedding dimension to 64. The model will be trained for 30 epochs with a split ratio of 80% for training, 10% for validation, and 10% for testing.\n",
    "\n",
    "After training the model, we will use it to make predictions on three specific nodes: \"brazil\", \"uk\", and \"jordan\". We will predict the top 3 relationships for each node and print the results.\n",
    "\n",
    "Finally, we will create new relationships in the graph based on the predicted relationships. For each predicted relationship, we will create a new relationship between the corresponding nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d518e67375f6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.set_compute_cluster_ip(\"localhost\")\n",
    "\n",
    "model_name = \"dummyModelName_\" + str(time.time())\n",
    "\n",
    "gds.kge.model.train(\n",
    "    G,\n",
    "    model_name=model_name,\n",
    "    scoring_function=\"DistMult\",\n",
    "    num_epochs=30,\n",
    "    embedding_dimension=64,\n",
    "    split_ratios={\"TRAIN\": 0.8, \"VALID\": 0.1, \"TEST\": 0.1},\n",
    "    mlflow_experiment_name=\"Nations-train\",\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "predict_result = gds.kge.model.predict(\n",
    "    model_name=model_name,\n",
    "    top_k=3,\n",
    "    node_ids=[\n",
    "        gds.find_node_id([\"Entity\"], {\"text\": \"brazil\"}),\n",
    "        gds.find_node_id([\"Entity\"], {\"text\": \"uk\"}),\n",
    "        gds.find_node_id([\"Entity\"], {\"text\": \"jordan\"}),\n",
    "    ],\n",
    "    rel_types=[\"REL_RELDIPLOMACY\", \"REL_RELNGO\"],\n",
    ")\n",
    "\n",
    "print(predict_result.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa583359",
   "metadata": {},
   "source": [
    "In the next cell we will add this top scored relationships to te database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b75194c69259a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in predict_result.iterrows():\n",
    "    h = row[\"sourceNodeId\"]\n",
    "    r = row[\"rel\"]\n",
    "    gds.run_cypher(\n",
    "        f\"\"\"\n",
    "        UNWIND $tt as t\n",
    "        MATCH (a:Entity WHERE id(a) = {h})\n",
    "        MATCH (b:Entity WHERE id(b) = t)\n",
    "        MERGE (a)-[:NEW_REL_{r}]->(b)\n",
    "    \"\"\",\n",
    "        params={\"tt\": row[\"targetNodeIdTopK\"]},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00579a8",
   "metadata": {},
   "source": [
    "There is also a API that can be used to score a list of triplets. In the next cell we will use a call to score the triplets `(brazil, REL_RELNGO, uk)` and `(brazil, REL_RELDIPLOMACY, jordan)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil_node = gds.find_node_id([\"Entity\"], {\"text\": \"brazil\"})\n",
    "uk_node = gds.find_node_id([\"Entity\"], {\"text\": \"uk\"})\n",
    "jordan_node = gds.find_node_id([\"Entity\"], {\"text\": \"jordan\"})\n",
    "\n",
    "triplets = [\n",
    "    (brazil_node, \"REL_RELNGO\", uk_node),\n",
    "    (brazil_node, \"REL_RELDIPLOMACY\", jordan_node),\n",
    "]\n",
    "\n",
    "scores = gds.kge.model.score_triplets(\n",
    "    model_name=model_name,\n",
    "    triplets=triplets,\n",
    ")\n",
    "\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
