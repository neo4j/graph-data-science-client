{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "aura"
    ]
   },
   "source": [
    "# Running GDS workloads on data hosted in AuraDB\n",
    "\n",
    "The new Project ðŸ“ (Strawberry) is a new way to run GDS on data hosted in an AuraDB database.\n",
    "The way to do this currently in Aura is to copy the database over to an AuraDS instance, which is itself a database service (single instance).\n",
    "This detaches the data and the two databases will likely diverge almost immediately.\n",
    "It also has another couple of limitations:\n",
    "\n",
    "- It's very manual; users have to click in the Aura Console to copy the database\n",
    "- Once GDS computations are finished, writing back to the AuraDB instance is also a manual configuration\n",
    "- AuraDS instances have to be manually managed in the Aura Console and do not encourage users to delete them after usage, thus causing increased running costs\n",
    "\n",
    "With Project ðŸ“ we're addressing the top two limitations, and alleviating the final one a little bit.\n",
    "\n",
    "## AuraDB\n",
    "\n",
    "A base assumption is that there is an AuraDB already with data in it.\n",
    "In this notebook, we will illustrate using some tiny example graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to begin, let's make sure we have the correct version of the GDS Python Client installed\n",
    "\n",
    "from graphdatascience import __version__\n",
    "\n",
    "assert __version__ == \"1.9a1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to configure access to our AuraDB instance. Please fill in the instance id and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_id = \"YOUR_DATABASE_ID\"\n",
    "db_password = \"YOUR_DATABASE_PASSWORD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we connect to the AuraDB instance to and run some preparations for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience.gds_session.dbms_connection_info import DbmsConnectionInfo\n",
    "import os\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# We need to tell the GDS client that we are working with a development environment.\n",
    "# This does not need to be set in production.\n",
    "os.environ[\"AURA_ENV\"] = \"devstrawberryfield\"\n",
    "\n",
    "db_connection_info = DbmsConnectionInfo(\n",
    "    f\"neo4j+s://{db_id}-{os.environ['AURA_ENV']}.databases.neo4j-dev.io\", \"neo4j\", db_password\n",
    ")\n",
    "# start a standard Neo4j Python Driver to connect to the AuraDB instance\n",
    "driver = GraphDatabase.driver(db_connection_info.uri, auth=db_connection_info.auth())\n",
    "\n",
    "# try out our connection\n",
    "with driver.session() as session:\n",
    "    display(session.run(\"RETURN true AS success\").to_df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some very basic data to our database. \n",
    "The content does not really matter for this notebook, feel free to replace it with more interesting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT users FOR (u:User) REQUIRE u.id IS NODE KEY\")\n",
    "    session.run(\"CREATE CONSTRAINT products FOR (p:Product) REQUIRE p.id IS NODE KEY\")\n",
    "    session.run(\n",
    "        \"\"\"\n",
    "        UNWIND range(0, 999) AS i\n",
    "        CREATE (:User {id: i, age: toInteger(rand() * 75)})\n",
    "        \"\"\"\n",
    "    ).consume()\n",
    "    session.run(\n",
    "        \"\"\"\n",
    "        UNWIND range(0, 99) AS i\n",
    "        CREATE (:Product {id: i, cost: rand() * 200})\n",
    "        \"\"\"\n",
    "    ).consume()\n",
    "    session.run(\n",
    "        \"\"\"\n",
    "        UNWIND range(1, 8000) AS i\n",
    "        WITH toInteger(rand() * 1000) AS source, toInteger(rand() * 1000) AS target\n",
    "        MATCH (s:User {id: source})\n",
    "        MATCH (t:User {id: target})\n",
    "        CREATE (s)-[:KNOWS {since: 2020 - (rand() * 100)}]->(t)\n",
    "        \"\"\"\n",
    "    ).consume()\n",
    "    session.run(\n",
    "        \"\"\"\n",
    "        UNWIND range(1, 2000) AS i\n",
    "        WITH toInteger(rand() * 1000) AS source, toInteger(rand() * 100) AS target\n",
    "        MATCH (s:User {id: source})\n",
    "        MATCH (t:Product {id: target})\n",
    "        CREATE (s)-[:BOUGHT {price: t.cost * (1 + rand())}]->(t)\n",
    "        \"\"\"\n",
    "    ).consume()\n",
    "\n",
    "    print(f\"Number of nodes: {session.run('MATCH () RETURN count(*)').single().value()}\")\n",
    "    print(f\"Number of relationships: {session.run('MATCH ()-->() RETURN count(*)').single().value()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A new database component: Arrow Server\n",
    "\n",
    "We have built a new piece of software into the Neo4j DBMS: an Arrow Server.\n",
    "It is akin to the already existing Bolt and HTTP servers, but with a more narrow purpose: projecting graphs to a remote location, and receiving results to write back to the database.\n",
    "\n",
    "With the Arrow Server comes one crucial new feature: an aggregating projection function.\n",
    "This aggregating function is called `gds.graph.project.remote` and is very similar to Cypher projection v2 in standard GDS.\n",
    "There are three key differences between them:\n",
    "\n",
    "1. In AuraDB, the aggregating function does not take a graph name as a parameter.\n",
    "2. In AuraDB, the aggregating function does not project the graph to the local server.\n",
    "3. The aggregation function should only be called through the GDS Python Client.\n",
    "\n",
    "The aggregating function is used in queries that look quite identical to those of Cypher projections v2, and are authored by the user.\n",
    "\n",
    "There is another function that comes with the Arrow Server, which is internal, undocumented, but is callable: `internal.arrow.status`.\n",
    "It is used as a crucial part of the GDS Python Client functionality for managing the AuraDB - GDS connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call this function and see what it returns\n",
    "with driver.session() as session:\n",
    "    display(session.run(\"CALL internal.arrow.status\").to_df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aura API and GDS Python Client\n",
    "\n",
    "Apart from the extension to AuraDB, we have also added a new API to the GDS Python Client.\n",
    "This API is a Python frontend to the Aura API, as well as a set of internal management features for the AuraDB - GDS connection.\n",
    "In order to use the Aura API, the user needs to have Aura API credentials.\n",
    "These are generated in the Aura Console (under `Account settings`) and are a pair of strings: `CLIENT_ID` and `CLIENT_SECRET`.\n",
    "\n",
    "Using these credentials the full set of features offered by the GDS Python Client can be used.\n",
    "In particular, the features are:\n",
    "\n",
    "- Create a new GDS session\n",
    "- (Re-)connect to an existing GDS session\n",
    "- List all existing GDS sessions\n",
    "- Delete a GDS session\n",
    "\n",
    "We will illustrate what this looks like below.\n",
    "\n",
    "## Tenants\n",
    "\n",
    "If the user is a member of multiple tenants, then they also need to enter their tenant id, in order to disambiguate which tenant they want to use.\n",
    "In this notebook, we will use only a single tenant and omit the tenant id. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Aura API credentials\n",
    "CLIENT_ID = \"YOUR_AURA_API_CLIENT_ID\"\n",
    "CLIENT_SECRET = \"YOUR_AURA_API_CLIENT_SECRET\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The GDS session\n",
    "\n",
    "A key new concept is the GDS session.\n",
    "This takes the place of an AuraDS instance.\n",
    "(In fact, it is exactly an AuraDS instance at this time, but we don't want to expose that to the user.\n",
    "They should think of it as a GDS session and a separate thing, as much as possible.)\n",
    "The GDS session offers all the GDS functionality that we are familiar with from AuraDS.\n",
    "However, since the idea is to offload database work to AuraDB, the GDS session is not to be considered a database service.\n",
    "As such, any standard Cypher queries run through the client's `run_cypher` method will not be executed on the GDS session, but on the AuraDB instance.\n",
    "\n",
    "All projections will go from AuraDB to GDS session, not from a co-located database.\n",
    "Similarly, writing back will follow the same path back to AuraDB, and not to a co-located database.\n",
    "\n",
    "## Implementation limitation\n",
    "\n",
    "As mentioned in the parenthesis above, we do make use of existing AuraDS infrastructure to host the GDS sessions.\n",
    "Due to that fact, there actually is a co-located database, but we try to not expose its Bolt URI, in an attempt to prohibit users adding data to that database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new stuff!\n",
    "from graphdatascience.gds_session.gds_sessions import GdsSessions, AuraAPICredentials\n",
    "\n",
    "# Create a new AuraSessions object\n",
    "sessions = GdsSessions(ds_connection=AuraAPICredentials(CLIENT_ID, CLIENT_SECRET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing sessions\n",
    "\n",
    "A user can list their running sessions.\n",
    "By default no session is running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a new session\n",
    "\n",
    "A new session is created by calling `sessions.get_or_create()`.\n",
    "Creating a new session takes a few minutes to complete.\n",
    "\n",
    "## Session sizes\n",
    "\n",
    "A session is identified by a name and needs a size to be specified.\n",
    "Session sizes are logical and specified using the `SessionSizes.by_memory()` enum.\n",
    "Possible values are `DEFAULT`, `XS`, `S`, `SM`, `M`, `ML`, `L`, `XL`, `XXL`, `X3L`, `X4L`, `X5L`.\n",
    "\n",
    "## Database connection\n",
    "\n",
    "A GDS Session is by default connected to an AuraDB instance.\n",
    "In order to connect successfully, address and credentials for the AuraDB instance must be specified. \n",
    "It is possible to specify connection information for a self-managed Neo4j DBMS instance (even localhost), but this requires enabling the Arrow Server on that instance.\n",
    "Documentation for how to do that is not yet available.\n",
    "\n",
    "## Session cost \n",
    "\n",
    "The creation of a session marks the start of billable activity.\n",
    "Sessions are machines that run in the cloud, and they cost money.\n",
    "This cost will accumulate for the lifetime of the session, which needs to be manually deleted (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience.gds_session.session_sizes import SessionSizes\n",
    "\n",
    "# let's create a GDS session!\n",
    "gds = sessions.get_or_create(\n",
    "    session_name=\"pagerank-compute\",\n",
    "    size=SessionSizes.by_memory().DEFAULT,\n",
    "    db_connection=db_connection_info,\n",
    ")\n",
    "\n",
    "# If we had already created a session and want to reconnect to it, the same code is used.\n",
    "# Doing that will not incur any additional costs, and will be a lot faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projecting Graphs\n",
    "\n",
    "In order to project graphs from an AuraDB instance into the GDS session we created a new projection method: `gds.graph.project.remote`\n",
    "The projection works similar to Cypher projections V2 and is implemented as a Cypher aggregating function.\n",
    "The Cypher query containing the projection function is executed on the AuraDB instance and the data it produces is transferred to the GDS session instance via an Arrow connection. \n",
    "\n",
    "There are two key differences between the remote projection and Cypher projections V2:\n",
    "\n",
    "1. In AuraDB, the aggregating function does not take a graph name as a parameter.\n",
    "2. The aggregation function should only be called through the GDS Python Client endpoint `gds.graph.project`.\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Apart from the configuration passed into the aggregating function itself and which varies row by row, there is also configuration for the projection as a whole. \n",
    "The remote projection endpoint is configured using the following parameters:\n",
    "\n",
    "- `graph_name`: The name of the graph. Mandatory.\n",
    "- `query`: The query with the aggregating function. Mandatory.\n",
    "- `undirectedRelationships`: A list of relationship types that should be projected as undirected. Optional.\n",
    "- `inverseIndexedRelationships`: A list of relationship types that should be projected also inversely indexed. Optional.\n",
    "- `nodePropertySchema`: A map of property keys (strings) to its target property type. Optional.\n",
    "- `relationshipPropertySchema`: A map of property keys (strings) to its target property type. Optional.\n",
    "\n",
    "While specifying the two schema parameters is optional, it is recommended to do so.\n",
    "When these are not specified, the projection query will have to make sure that every row contains the full node and relationship schema for automatic inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience.gds_session.schema import GdsPropertyTypes\n",
    "\n",
    "G, result = gds.graph.project(\n",
    "    \"pagerank-graph\",\n",
    "    \"\"\"\n",
    "    CALL {\n",
    "        MATCH (u1:User)\n",
    "        OPTIONAL MATCH (u1)-[r:KNOWS]->(u2:User)\n",
    "        RETURN u1 AS source, r AS rel, u2 AS target, {age: u1.age} AS sourceNodeProperties, {} AS targetNodeProperties\n",
    "        UNION\n",
    "        MATCH (p:Product)\n",
    "        OPTIONAL MATCH (p)<-[r:BOUGHT]-(user:User)\n",
    "        RETURN user AS source, r AS rel, p AS target, {} AS sourceNodeProperties, {cost: p.cost} AS targetNodeProperties\n",
    "    }\n",
    "    RETURN gds.graph.project.remote(source, target, {\n",
    "      sourceNodeProperties: sourceNodeProperties,\n",
    "      targetNodeProperties: targetNodeProperties,\n",
    "      sourceNodeLabels: labels(source),\n",
    "      targetNodeLabels: labels(target),\n",
    "      relationshipType: type(rel),\n",
    "      relationshipProperties: properties(rel)\n",
    "    })\n",
    "    \"\"\",\n",
    "    nodePropertySchema={\"age\": GdsPropertyTypes.LONG, \"cost\": GdsPropertyTypes.DOUBLE},\n",
    "    relationshipPropertySchema={\"since\": GdsPropertyTypes.DOUBLE, \"price\": GdsPropertyTypes.DOUBLE},\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Algorithms\n",
    "\n",
    "Running algorithms on the projected graph works exactly the same as with standard GDS, particularly when running `stream`, `stats`, and `mutate` modes.\n",
    "Mutated algorithm results will be stored in the in-memory graph catalog of the GDS Session and the data can be retrieved via the stream operations on the graph like `gds.graph.nodeProperty.stream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running PageRank ...\")\n",
    "pr_result = gds.pageRank.mutate(G, mutateProperty=\"pagerank\")\n",
    "print(f\"Compute millis: {pr_result['computeMillis']}\")\n",
    "print(f\"Node properties written: {pr_result['nodePropertiesWritten']}\")\n",
    "print(f\"Centrality distribution: {pr_result['centralityDistribution']}\")\n",
    "\n",
    "print(\"Running FastRP ...\")\n",
    "frp_result = gds.fastRP.mutate(\n",
    "    G,\n",
    "    mutateProperty=\"fastRP\",\n",
    "    embeddingDimension=64,\n",
    "    featureProperties=[\"pagerank\"],\n",
    "    propertyRatio=0.2,\n",
    "    nodeSelfInfluence=0.2,\n",
    ")\n",
    "print(f\"Compute millis: {frp_result['computeMillis']}\")\n",
    "gds.graph.nodeProperties.stream(G, [\"pagerank\", \"fastRP\"], separate_property_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing back to AuraDB\n",
    "\n",
    "The GDS Session's in-memory graph was projected from data in AuraDB.\n",
    "Write back operations will thus persist the data back to the same AuraDB.\n",
    "\n",
    "When calling any write operations the GDS Python client will automatically use the new remote write back functionality so that no API changes are necessary.\n",
    "\n",
    "The AuraDB coordinates are not stored in the GDS session, but in the client.\n",
    "Thus, it is important to use DB credentials that identify the correct database from which the projection came, in the case where the `get_or_create()` method was used to reconnect to an existing session (the `get` case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this fails once with some error like \"unable to retrieve routing table\"\n",
    "# then run it again. this is a transient error with a stale server cache.\n",
    "gds.graph.nodeProperties.write(G, \"pagerank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can just use `.write` modes as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.fastRP.write(\n",
    "    G,\n",
    "    writeProperty=\"fastRP\",\n",
    "    embeddingDimension=64,\n",
    "    featureProperties=[\"pagerank\"],\n",
    "    propertyRatio=0.2,\n",
    "    nodeSelfInfluence=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `gds.run_cypher()` method to query the updated graph.\n",
    "Note that the `run_cypher()` method will run the query on the AuraDB instance.\n",
    "The GDS Session is not a database service, so it does not support Cypher queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (u:User) \n",
    "    RETURN u.id, u.age, u.fastRP, u.pagerank AS rank \n",
    "     ORDER BY rank DESC\n",
    "     LIMIT 5\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also do arbitrary write queries in the same way\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    CREATE (myNode:MyNode {prop: 1})\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "gds.run_cypher(\n",
    "    \"\"\"\n",
    "    MATCH (myNode:MyNode)\n",
    "    RETURN myNode.prop\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting the session\n",
    "\n",
    "The idea is that a GDS Session should only live for the time it takes to run a single, complete workload.\n",
    "If the same workload needs to be re-run, for example to work with updated data, a new session should be created.\n",
    "This is because the GDS Session is not a database service, but a compute service.\n",
    "If it is not computing, it should be deleted to avoid unnecessary costs.\n",
    "\n",
    "The `session.delete()` operation will delete the session and release all resources associated with it.\n",
    "It is important to note that until this command is called, running the session is associated with billable costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will return True if it did delete something\n",
    "# it will return False otherwise, but it will not normally fail\n",
    "sessions.delete(\"pagerank-compute\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
