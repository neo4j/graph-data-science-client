{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "aura"
    ]
   },
   "source": [
    "# Graph Analytics Serverless for non-Neo4j data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neo4j/graph-data-science-client/blob/main/examples/graph-analytics-serverless-standalone.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook is hosted [here](https://github.com/neo4j/graph-data-science-client/blob/main/examples/graph-analytics-serverless-standalone.ipynb) in the Neo4j Graph Data Science Client Github repository.\n",
    "\n",
    "The notebook shows how to use the `graphdatascience` Python library to create, manage, and use a GDS Session.\n",
    "\n",
    "We consider a graph of people and fruits, which we're using as a simple example to show how to load data from Pandas `DataFrame` to a GDS Session, run algorithms, and inspect the results. \n",
    "We will cover all management operations: creation, listing, and deletion.\n",
    "\n",
    "If you are using AuraDB, follow [this example](../graph-analytics-serverless).\n",
    "If you are using a self-managed Neo4j instance, follow [this example](../graph-analytics-serverless-self-managed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook requires having the Graph Analytics Serverless [feature](https://neo4j.com/docs/aura/graph-analytics/#aura-gds-serverless) enabled for your Neo4j Aura project. \n",
    "\n",
    "You also need to have the `graphdatascience` Python library installed, version `1.15` or later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "verify-version"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install \"graphdatascience>=1.15\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aura API credentials\n",
    "\n",
    "The entry point for managing GDS Sessions is the `GdsSessions` object, which requires creating [Aura API credentials](https://neo4j.com/docs/aura/api/authentication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from graphdatascience.session import AuraAPICredentials, GdsSessions\n",
    "\n",
    "client_id = os.environ[\"AURA_API_CLIENT_ID\"]\n",
    "client_secret = os.environ[\"AURA_API_CLIENT_SECRET\"]\n",
    "\n",
    "# If your account is a member of several projects, you must also specify the project ID to use\n",
    "project_id = os.environ.get(\"AURA_API_PROJECT_ID\", None)\n",
    "\n",
    "sessions = GdsSessions(api_credentials=AuraAPICredentials(client_id, client_secret, project_id=project_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new session\n",
    "\n",
    "\n",
    "A new session is created by calling `sessions.get_or_create()` with the following parameters:\n",
    "* A session name, which lets you reconnect to an existing session by calling `get_or_create` again.\n",
    "* The session memory.\n",
    "* The cloud location.\n",
    "* A time-to-live (TTL), which ensures that the session is automatically deleted after being unused for the set time, to avoid incurring costs.\n",
    "\n",
    "See the API reference [documentation](https://neo4j.com/docs/graph-data-science-client/current/api/sessions/gds_sessions/#graphdatascience.session.gds_sessions.GdsSessions.get_or_create) or the manual for more details on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience.session import AlgorithmCategory, CloudLocation, SessionMemory\n",
    "\n",
    "# Explicitly define the size of the session\n",
    "memory = SessionMemory.m_4GB\n",
    "\n",
    "# Estimate the memory needed for the GDS session\n",
    "memory = sessions.estimate(\n",
    "    node_count=20,\n",
    "    relationship_count=50,\n",
    "    algorithm_categories=[AlgorithmCategory.CENTRALITY, AlgorithmCategory.NODE_EMBEDDING],\n",
    ")\n",
    "\n",
    "print(f\"Estimated memory: {memory}\")\n",
    "\n",
    "# Specify your cloud location\n",
    "cloud_location = CloudLocation(\"gcp\", \"europe-west1\")\n",
    "\n",
    "# You can find available cloud locations by calling\n",
    "cloud_locations = sessions.available_cloud_locations()\n",
    "print(f\"Available locations: {cloud_locations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# Create a GDS session!\n",
    "gds = sessions.get_or_create(\n",
    "    # we give it a representative name\n",
    "    session_name=\"people-and-fruits-standalone\",\n",
    "    memory=memory,\n",
    "    ttl=timedelta(minutes=30),\n",
    "    cloud_location=cloud_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing sessions\n",
    "\n",
    "You can use `sessions.list()` to see the details for each created session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "gds_sessions = sessions.list()\n",
    "\n",
    "# for better visualization\n",
    "DataFrame(gds_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a dataset\n",
    "\n",
    "We assume that the configured Neo4j database instance is empty.\n",
    "We will add our dataset using standard Cypher.\n",
    "\n",
    "In a more realistic scenario, this step is already done, and we would just connect to the existing database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "people_df = pd.DataFrame(\n",
    "    [\n",
    "        {\"nodeId\": 0, \"name\": \"Dan\", \"age\": 18, \"experience\": 63, \"hipster\": 0},\n",
    "        {\"nodeId\": 1, \"name\": \"Annie\", \"age\": 12, \"experience\": 5, \"hipster\": 0},\n",
    "        {\"nodeId\": 2, \"name\": \"Matt\", \"age\": 22, \"experience\": 42, \"hipster\": 0},\n",
    "        {\"nodeId\": 3, \"name\": \"Jeff\", \"age\": 51, \"experience\": 12, \"hipster\": 0},\n",
    "        {\"nodeId\": 4, \"name\": \"Brie\", \"age\": 31, \"experience\": 6, \"hipster\": 0},\n",
    "        {\"nodeId\": 5, \"name\": \"Elsa\", \"age\": 65, \"experience\": 23, \"hipster\": 0},\n",
    "        {\"nodeId\": 6, \"name\": \"Bobby\", \"age\": 38, \"experience\": 4, \"hipster\": 1},\n",
    "        {\"nodeId\": 7, \"name\": \"John\", \"age\": 4, \"experience\": 100, \"hipster\": 0},\n",
    "    ]\n",
    ")\n",
    "people_df[\"labels\"] = \"Person\"\n",
    "\n",
    "fruits_df = pd.DataFrame(\n",
    "    [\n",
    "        {\"nodeId\": 8, \"name\": \"Apple\", \"tropical\": 0, \"sourness\": 0.3, \"sweetness\": 0.6},\n",
    "        {\"nodeId\": 9, \"name\": \"Banana\", \"tropical\": 1, \"sourness\": 0.1, \"sweetness\": 0.9},\n",
    "        {\"nodeId\": 10, \"name\": \"Mango\", \"tropical\": 1, \"sourness\": 0.3, \"sweetness\": 1.0},\n",
    "        {\"nodeId\": 11, \"name\": \"Plum\", \"tropical\": 0, \"sourness\": 0.5, \"sweetness\": 0.8},\n",
    "    ]\n",
    ")\n",
    "fruits_df[\"labels\"] = \"Fruit\"\n",
    "\n",
    "like_relationships = [(0, 8), (1, 9), (2, 10), (3, 10), (4, 9), (5, 11), (7, 11)]\n",
    "likes_df = pd.DataFrame([{\"sourceNodeId\": src, \"targetNodeId\": trg} for (src, trg) in like_relationships])\n",
    "likes_df[\"relationshipType\"] = \"LIKES\"\n",
    "\n",
    "knows_relationship = [(0, 1), (0, 2), (1, 2), (1, 3), (1, 4), (2, 5), (7, 3)]\n",
    "knows_df = pd.DataFrame([{\"sourceNodeId\": src, \"targetNodeId\": trg} for (src, trg) in knows_relationship])\n",
    "knows_df[\"relationshipType\"] = \"KNOWS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph from DataFrames\n",
    "\n",
    "Now that we have imported a graph to our database, we create graphs directly from pandas `DataFrame` objects.\n",
    "We do that by using the `gds.graph.construct()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping `name` column as GDS does not support string properties\n",
    "nodes = [people_df.drop(columns=\"name\"), fruits_df.drop(columns=\"name\")]\n",
    "relationships = [likes_df, knows_df]\n",
    "\n",
    "G = gds.graph.construct(\"people-fruits\", nodes, relationships)\n",
    "str(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Algorithms\n",
    "\n",
    "You can run algorithms on the constructed graph using the standard GDS Python Client API. See the other tutorials for more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running PageRank ...\")\n",
    "pr_result = gds.pageRank.mutate(G, mutateProperty=\"pagerank\")\n",
    "print(f\"Compute millis: {pr_result['computeMillis']}\")\n",
    "print(f\"Node properties written: {pr_result['nodePropertiesWritten']}\")\n",
    "print(f\"Centrality distribution: {pr_result['centralityDistribution']}\")\n",
    "\n",
    "print(\"Running FastRP ...\")\n",
    "frp_result = gds.fastRP.mutate(\n",
    "    G,\n",
    "    mutateProperty=\"fastRP\",\n",
    "    embeddingDimension=8,\n",
    "    featureProperties=[\"pagerank\"],\n",
    "    propertyRatio=0.2,\n",
    "    nodeSelfInfluence=0.2,\n",
    ")\n",
    "print(f\"Compute millis: {frp_result['computeMillis']}\")\n",
    "# stream back the results\n",
    "result = gds.graph.nodeProperties.stream(G, [\"pagerank\", \"fastRP\"], separate_property_columns=True)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To resolve each `nodeId` to name, we can merge it back with the source data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.concat([people_df, fruits_df])[[\"nodeId\", \"name\"]]\n",
    "result.merge(names, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the session\n",
    "\n",
    "After the analysis is done, you can delete the session.\n",
    "As this example is not connected to a Neo4j DB, you need to make sure the algorithm results are persisted on your own.\n",
    "\n",
    "Deleting the session will release all resources associated with it, and stop incurring costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "teardown"
    ]
   },
   "outputs": [],
   "source": [
    "# or gds.delete()\n",
    "sessions.delete(session_name=\"people-and-fruits-standalone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also make sure the deleted session is truly gone:\n",
    "sessions.list()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
